import os
import requests
import json
import sqlite3
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from Bio import Entrez
from openai import OpenAI

# ===================== [í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ] =====================
# GitHub Actionsì— ë“±ë¡í•  ë¹„ë°€í‚¤ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
EMAIL_ADDRESS = os.environ.get("EMAIL_ADDRESS")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

Entrez.email = EMAIL_ADDRESS
client = OpenAI(api_key=OPENAI_API_KEY)

# ===================== [í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤] =====================
# (ê¸°ì¡´ app.pyì˜ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ë˜, Streamlit ê´€ë ¨ ì½”ë“œëŠ” ì œê±°)

def fetch_pmc_fulltext(pmid):
    try:
        link_results = Entrez.elink(dbfrom="pubmed", db="pmc", id=pmid)
        if not link_results or not link_results[0]['LinkSetDb']: return None, "Abstract Only"
        pmc_id = link_results[0]['LinkSetDb'][0]['Link'][0]['Id']
        handle = Entrez.efetch(db="pmc", id=pmc_id, rettype="xml")
        root = ET.fromstring(handle.read())
        full_text = "".join([t for t in root.itertext()])
        return full_text[:20000], "âœ… Full Text (PMC)"
    except: return None, "Error"

def search_papers_yesterday():
    # ì–´ì œ ë‚ ì§œ ê¸°ì¤€ ê²€ìƒ‰
    yesterday = datetime.now() - timedelta(days=1)
    date_str = yesterday.strftime("%Y/%m/%d")
    
    search_term = """
    ("TCM" OR "Traditional chinese medicine" OR "Herbal medicine" OR "Acupuncture" OR "Chuna") 
    AND (hasabstract[text]) AND ("Humans"[Mesh]) 
    AND ("Case Reports"[ptyp] OR "Clinical Trial"[ptyp] OR "Randomized Controlled Trial"[ptyp] OR "Systematic Review"[ptyp])
    """
    try:
        handle = Entrez.esearch(db="pubmed", term=search_term, mindate=date_str, maxdate=date_str, datetype="pdat", retmax=10)
        record = Entrez.read(handle)
        return record["IdList"]
    except: return []

def analyze_and_generate_briefing(id_list):
    if not id_list: return "ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ì„ìƒ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
    
    analyzed_data = []
    # ìƒìœ„ 5ê°œë§Œ ë¶„ì„
    for pmid in id_list[:5]: 
        try:
            handle = Entrez.efetch(db="pubmed", id=pmid, rettype="medline", retmode="xml")
            article = Entrez.read(handle)['PubmedArticle'][0]
            title = article['MedlineCitation']['Article']['ArticleTitle']
            abstract = article['MedlineCitation']['Article']['Abstract']['AbstractText'][0]
            
            full_text, status = fetch_pmc_fulltext(pmid)
            content = full_text if full_text else abstract
            
            # PICO ë¶„ì„ (GPT-4o-minië¡œ ìš”ì•½)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{
                    "role": "user", 
                    "content": f"ì´ ë…¼ë¬¸ì„ í•œê¸€ë¡œ PICO ìš”ì•½í•´ì¤˜. (ì•½ì–´ëŠ” í’€ë„¤ì„ìœ¼ë¡œ)\nTitle: {title}\nContent: {content[:10000]}"
                }]
            )
            summary = response.choices[0].message.content
            analyzed_data.append(f"ğŸ”¹ **[{title}]**\n(ì†ŒìŠ¤: {status})\n{summary}\nğŸ”— https://pubmed.ncbi.nlm.nih.gov/{pmid}\n")
        except: continue

    # ìµœì¢… ë¸Œë¦¬í•‘ ì‘ì„± (GPT-4o)
    today_str = datetime.now().strftime("%Y-%m-%d")
    prompt = f"""
    ì•„ë˜ ë…¼ë¬¸ ìš”ì•½ë³¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ 'í•œì˜ì‚¬ {today_str} ë°ì¼ë¦¬ ì„ìƒ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì¤˜.
    í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ìš©ì´ë¯€ë¡œ ê°€ë…ì„± ì¢‹ê²Œ, ì´ëª¨ì§€ ì‚¬ìš©í•´ì„œ ì‘ì„±í•´.
    
    [ë…¼ë¬¸ ë°ì´í„°]
    {"".join(analyzed_data)}
    """
    
    final_res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )
    return final_res.choices[0].message.content

# ===================== [ì „ì†¡ í•¨ìˆ˜] =====================
def send_telegram(message):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": message, "parse_mode": "Markdown"}
    requests.post(url, json=payload)

# ===================== [ì‹¤í–‰ë¶€] =====================
if __name__ == "__main__":
    print("ğŸš€ ìë™í™” ë´‡ ì‹œì‘...")
    pmids = search_papers_yesterday()
    print(f"ê²€ìƒ‰ëœ ë…¼ë¬¸: {len(pmids)}ê±´")
    
    if pmids:
        briefing_text = analyze_and_generate_briefing(pmids)
        print("ë¸Œë¦¬í•‘ ìƒì„± ì™„ë£Œ. ì „ì†¡ ì¤‘...")
        send_telegram(briefing_text)
        # ì—¬ê¸°ì— post_to_blog(briefing_text) í•¨ìˆ˜ë§Œ ì¶”ê°€í•˜ë©´ ë¸”ë¡œê·¸ë„ ìë™ ì—…ë¡œë“œ ë¨
        print("âœ… ì „ì†¡ ì™„ë£Œ!")
    else:
        send_telegram("ì˜¤ëŠ˜ì€ ê²€ìƒ‰ëœ ì„ìƒ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. í‘¹ ì‰¬ì„¸ìš”! â˜•")